{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import jieba\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载docx文档\n",
    "def load_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = []\n",
    "    for para in doc.paragraphs:\n",
    "        text.append(para.text)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "# 使用jieba进行中文分词\n",
    "def jieba_tokenizer(text):\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# 将文本转换为TF-IDF向量\n",
    "def text_to_tfidf(texts):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=jieba_tokenizer)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts).toarray()\n",
    "    return tfidf_matrix, vectorizer\n",
    "\n",
    "# 使用FAISS进行相似度检索\n",
    "def search_similar_sentences(query_vector, index, k=3):\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例用法\n",
    "docx_path = 'test.docx'  # 替换为你的docx文件路径\n",
    "keywords = ['前锋', '中场', '后卫', '守门员']  # 你要查找的多个关键词\n",
    "\n",
    "# 加载文档内容\n",
    "doc_text = load_docx(docx_path)\n",
    "\n",
    "# 按段落分割文本\n",
    "sentences = doc_text.split('\\n')\n",
    "\n",
    "# 将文本转换为TF-IDF向量\n",
    "tfidf_matrix, vectorizer = text_to_tfidf(sentences)\n",
    "\n",
    "# 构建FAISS索引\n",
    "dimension = tfidf_matrix.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(tfidf_matrix, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "查询关键词: 前锋\n",
      "最相似的 3 个句子:\n",
      "第 1 名: 前锋：刘诚宇（上海申花）、韦世豪（成都蓉城）、王子铭（北京国安）、张玉宁（北京国安）、林良铭（北京国安）、王钰栋（浙江）、拜合拉木·阿卜杜外力（深圳新鹏城）； (距离: 1.7755)\n",
      "第 2 名: 以下为国足世预赛18强赛大名单： (距离: 2.0000)\n",
      "\n",
      "查询关键词: 中场\n",
      "最相似的 3 个句子:\n",
      "第 1 名: 为备战18强赛，国足主教练伊万科维奇此前征召了32名球员，从3月3日起在阿联酋迪拜组织集训。随后球队又补招了山东泰山中场李源一入队。效力于北京国安的塞尔吉尼奥在3月14日正式获得代表中国队出场的资格。国足在15日的一场封闭热身赛中3:1击败科威特队，塞尔吉尼奥替补出场。 (距离: 1.8139)\n",
      "第 2 名: 中场：徐皓阳（上海申花）、汪海健（上海申花）、曹永竞（北京国安）、塞尔吉尼奥（北京国安）、李源一（山东泰山）、谢文能（山东泰山）、程进（浙江）、王上源（河南）； (距离: 1.8211)\n",
      "\n",
      "查询关键词: 后卫\n",
      "最相似的 3 个句子:\n",
      "第 1 名: 后卫：蒋光太（上海海港）、魏震（上海海港）、王振澳（上海海港）、杨泽翔（上海申花）、蒋圣龙（上海申花）、韩鹏飞（成都蓉城）、胡荷韬（成都蓉城）、李磊（北京国安）、高准翼（山东泰山）； (距离: 1.8265)\n",
      "第 2 名: 新华社北京3月16日电 16日，中国男足国家队公布了参加2026美加墨世界杯亚洲区预选赛18强赛第七和第八轮比赛的27人大名单，归化球员塞尔吉尼奥首次入选国家队，两位2006年出生的小将王钰栋、刘诚宇名列其中。 (距离: 2.0000)\n",
      "\n",
      "查询关键词: 守门员\n",
      "最相似的 3 个句子:\n",
      "第 1 名: 守门员：颜骏凌（上海海港）、刘殿座（成都蓉城）、王大雷（山东泰山）。 (距离: 1.5350)\n",
      "第 2 名: 为备战18强赛，国足主教练伊万科维奇此前征召了32名球员，从3月3日起在阿联酋迪拜组织集训。随后球队又补招了山东泰山中场李源一入队。效力于北京国安的塞尔吉尼奥在3月14日正式获得代表中国队出场的资格。国足在15日的一场封闭热身赛中3:1击败科威特队，塞尔吉尼奥替补出场。 (距离: 2.0000)\n"
     ]
    }
   ],
   "source": [
    "# 对每个关键词执行检索\n",
    "for keyword in keywords:\n",
    "    # 使用关键词生成查询向量\n",
    "    query_vector = vectorizer.transform([keyword]).toarray().astype(np.float32)\n",
    "\n",
    "    # 执行检索，查找最相似的3个句子\n",
    "    distances, indices = search_similar_sentences(query_vector, index, k=3)\n",
    "\n",
    "    # 打印查询结果\n",
    "    print(f\"\\n查询关键词: {keyword}\")\n",
    "    print(f\"最相似的 {len(distances[0])} 个句子:\")\n",
    "\n",
    "    for i in range(len(distances[0])):\n",
    "        sentence = sentences[indices[0][i]].strip()\n",
    "        # 如果句子不为空，则输出\n",
    "        if sentence:\n",
    "            print(f\"第 {i} 名: {sentence} (距离: {distances[0][i]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
